{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d78ecdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchvision import transforms\n",
    "from transformers import ViTModel\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe7e276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTI_ViT_Classifier(nn.Module):\n",
    "    \"\"\"ViT-based TTI Classifier matching the actual saved model structure\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(TTI_ViT_Classifier, self).__init__()\n",
    "\n",
    "        # Input processing layers (matching saved model naming)\n",
    "        self.first = nn.Conv2d(\n",
    "            5, 3, kernel_size=1, bias=False\n",
    "        )  # Maps to \"first.weight\"\n",
    "        self.pre_conv = nn.Conv2d(\n",
    "            5, 3, kernel_size=1, bias=False\n",
    "        )  # Maps to \"pre_conv.weight\"\n",
    "\n",
    "        # ViT backbone (matches \"backbone.*\" in saved model)\n",
    "        self.backbone = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "        # Classification head (matches \"fc.*\" in saved model)\n",
    "        self.fc = nn.Linear(768, num_classes)  # Direct linear layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convert 5-channel input to 3-channel using pre_conv\n",
    "        x = self.pre_conv(x)\n",
    "\n",
    "        # ViT forward pass\n",
    "        vit_outputs = self.backbone(pixel_values=x)\n",
    "\n",
    "        # Use [CLS] token representation\n",
    "        cls_output = vit_outputs.last_hidden_state[:, 0]\n",
    "\n",
    "        # Classification\n",
    "        logits = self.fc(cls_output)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DepthEstimator:\n",
    "    \"\"\"Simplified depth estimation (replace with actual Depth-Anything-V2-Small if available)\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Placeholder for actual depth model\n",
    "        self.transform = transforms.Compose(\n",
    "            [transforms.Resize((224, 224)), transforms.ToTensor()]\n",
    "        )\n",
    "\n",
    "    def estimate_depth(self, rgb_image):\n",
    "        \"\"\"\n",
    "        Estimate depth from RGB image\n",
    "        Returns normalized depth map [0, 1]\n",
    "        \"\"\"\n",
    "        # Convert to grayscale as simple depth proxy\n",
    "        if len(rgb_image.shape) == 3:\n",
    "            gray = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray = rgb_image\n",
    "\n",
    "        # Apply gaussian blur to simulate depth\n",
    "        depth = cv2.GaussianBlur(gray, (15, 15), 0)\n",
    "\n",
    "        # Normalize to [0, 1]\n",
    "        depth = depth.astype(np.float32) / 255.0\n",
    "\n",
    "        return depth\n",
    "\n",
    "\n",
    "class TTI_VideoInference:\n",
    "    \"\"\"TTI Model Inference Pipeline for Videos\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, model_path, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.model = self.load_model(model_path)\n",
    "        self.depth_estimator = DepthEstimator()\n",
    "\n",
    "        # Preprocessing transforms\n",
    "        self.transform = transforms.Compose(\n",
    "            [transforms.Resize((224, 224)), transforms.ToTensor()]\n",
    "        )\n",
    "\n",
    "        # Results storage\n",
    "        self.results = {\n",
    "            \"video_results\": [],\n",
    "            \"frame_predictions\": [],\n",
    "            \"summary_stats\": {},\n",
    "        }\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"Load the trained ViT model with flexible architecture matching\"\"\"\n",
    "        model = TTI_ViT_Classifier(num_classes=2)\n",
    "\n",
    "        try:\n",
    "            checkpoint = torch.load(model_path, map_location=self.device)\n",
    "\n",
    "            # Try to load the state dict directly\n",
    "            try:\n",
    "                model.load_state_dict(checkpoint)\n",
    "                print(f\"‚úì Loaded model from {model_path}\")\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Direct loading failed, trying flexible loading...\")\n",
    "\n",
    "                # Get model's state dict\n",
    "                model_dict = model.state_dict()\n",
    "\n",
    "                # Filter out layers that don't match\n",
    "                filtered_dict = {}\n",
    "                for k, v in checkpoint.items():\n",
    "                    if k in model_dict and model_dict[k].shape == v.shape:\n",
    "                        filtered_dict[k] = v\n",
    "                    else:\n",
    "                        print(f\"Skipping layer {k} (shape mismatch or not found)\")\n",
    "\n",
    "                # Load the filtered state dict\n",
    "                model_dict.update(filtered_dict)\n",
    "                model.load_state_dict(model_dict, strict=False)\n",
    "                print(\n",
    "                    f\"‚úì Loaded model with {len(filtered_dict)}/{len(checkpoint)} layers matched\"\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            print(\"Attempting to use one of the EfficientNet models instead...\")\n",
    "\n",
    "            # Fallback to EfficientNet-B3 (best performing according to docs)\n",
    "            return self.load_efficientnet_model(model_path.replace(\"ViT\", \"EffNet_B3\"))\n",
    "\n",
    "        model.to(self.device)\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    def load_efficientnet_model(self, model_path):\n",
    "        \"\"\"Fallback to load EfficientNet model\"\"\"\n",
    "        try:\n",
    "            from torchvision import models\n",
    "\n",
    "            # Create EfficientNet-B3 model\n",
    "            model = models.efficientnet_b3(pretrained=False)\n",
    "\n",
    "            # Modify for 5-channel input and 2-class output\n",
    "            model.features[0][0] = nn.Conv2d(\n",
    "                5, 40, kernel_size=3, stride=2, padding=1, bias=False\n",
    "            )\n",
    "            model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
    "\n",
    "            checkpoint = torch.load(model_path, map_location=self.device)\n",
    "            model.load_state_dict(checkpoint, strict=False)\n",
    "            print(f\"‚úì Loaded EfficientNet-B3 fallback model from {model_path}\")\n",
    "\n",
    "            model.to(self.device)\n",
    "            model.eval()\n",
    "            return model\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load fallback model: {e}\")\n",
    "            return None\n",
    "\n",
    "    def extract_roi_from_frame(self, frame, tool_mask=None, tissue_mask=None):\n",
    "        \"\"\"\n",
    "        Extract ROI based on tool-tissue interaction\n",
    "        For now, using the entire frame as ROI (modify based on actual mask availability)\n",
    "        \"\"\"\n",
    "        if tool_mask is not None and tissue_mask is not None:\n",
    "            # Calculate intersection\n",
    "            intersection_mask = cv2.bitwise_and(tool_mask, tissue_mask)\n",
    "\n",
    "            # Find bounding box of intersection\n",
    "            contours, _ = cv2.findContours(\n",
    "                intersection_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "            )\n",
    "\n",
    "            if contours:\n",
    "                # Get largest contour\n",
    "                largest_contour = max(contours, key=cv2.contourArea)\n",
    "                x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "                # Ensure minimum size (64x64 as per documentation)\n",
    "                w = max(w, 64)\n",
    "                h = max(h, 64)\n",
    "\n",
    "                # Extract ROI\n",
    "                roi = frame[y : y + h, x : x + w]\n",
    "                mask_roi = intersection_mask[y : y + h, x : x + w]\n",
    "            else:\n",
    "                # Fallback to center crop\n",
    "                roi = self.center_crop(frame, 224)\n",
    "                mask_roi = np.zeros((224, 224), dtype=np.uint8)\n",
    "        else:\n",
    "            # Use entire frame as ROI\n",
    "            roi = frame\n",
    "            mask_roi = np.ones((frame.shape[0], frame.shape[1]), dtype=np.uint8) * 255\n",
    "\n",
    "        return roi, mask_roi\n",
    "\n",
    "    def center_crop(self, image, size):\n",
    "        \"\"\"Center crop image to specified size\"\"\"\n",
    "        h, w = image.shape[:2]\n",
    "        start_h = max(0, (h - size) // 2)\n",
    "        start_w = max(0, (w - size) // 2)\n",
    "\n",
    "        cropped = image[start_h : start_h + size, start_w : start_w + size]\n",
    "\n",
    "        # Pad if necessary\n",
    "        if cropped.shape[0] < size or cropped.shape[1] < size:\n",
    "            cropped = cv2.resize(cropped, (size, size))\n",
    "\n",
    "        return cropped\n",
    "\n",
    "    def prepare_5channel_input(self, roi, mask_roi):\n",
    "        \"\"\"\n",
    "        Prepare 5-channel input as per documentation:\n",
    "        Channels 0-2: RGB values [0, 255]\n",
    "        Channel 3: Depth values [0, 1]\n",
    "        Channel 4: Interaction mask [0, 255]\n",
    "        \"\"\"\n",
    "        # Resize ROI to 224x224\n",
    "        roi_resized = cv2.resize(roi, (224, 224))\n",
    "        mask_resized = cv2.resize(mask_roi, (224, 224))\n",
    "\n",
    "        # Ensure RGB format\n",
    "        if len(roi_resized.shape) == 3 and roi_resized.shape[2] == 3:\n",
    "            rgb = roi_resized\n",
    "        else:\n",
    "            rgb = cv2.cvtColor(roi_resized, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        # Estimate depth\n",
    "        depth = self.depth_estimator.estimate_depth(rgb)\n",
    "\n",
    "        # Normalize inputs\n",
    "        rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "        depth_normalized = depth.astype(np.float32)  # Already [0, 1]\n",
    "        mask_normalized = mask_resized.astype(np.float32) / 255.0\n",
    "\n",
    "        # Stack channels: RGB + Depth + Mask\n",
    "        five_channel = np.zeros((5, 224, 224), dtype=np.float32)\n",
    "        five_channel[0:3] = np.transpose(rgb_normalized, (2, 0, 1))  # RGB channels\n",
    "        five_channel[3] = depth_normalized  # Depth channel\n",
    "        five_channel[4] = mask_normalized  # Mask channel\n",
    "\n",
    "        return torch.tensor(five_channel).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def predict_frame(self, frame, frame_idx, tool_mask=None, tissue_mask=None):\n",
    "        \"\"\"Predict TTI for a single frame\"\"\"\n",
    "        if self.model is None:\n",
    "            return None\n",
    "\n",
    "        # Extract ROI\n",
    "        roi, mask_roi = self.extract_roi_from_frame(frame, tool_mask, tissue_mask)\n",
    "\n",
    "        # Prepare 5-channel input\n",
    "        input_tensor = self.prepare_5channel_input(roi, mask_roi)\n",
    "\n",
    "        # Model inference\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(input_tensor)\n",
    "            probabilities = torch.softmax(logits, dim=1)\n",
    "            prediction = torch.argmax(logits, dim=1).item()\n",
    "            confidence = probabilities[0, prediction].item()\n",
    "\n",
    "        result = {\n",
    "            \"frame_idx\": frame_idx,\n",
    "            \"prediction\": prediction,  # 0: No-TTI, 1: TTI\n",
    "            \"confidence\": confidence,\n",
    "            \"probabilities\": {\n",
    "                \"No_TTI\": probabilities[0, 0].item(),\n",
    "                \"TTI\": probabilities[0, 1].item(),\n",
    "            },\n",
    "        }\n",
    "\n",
    "        return result\n",
    "\n",
    "    def process_video(self, video_path, sample_rate=30):\n",
    "        \"\"\"Process entire video and return predictions\"\"\"\n",
    "        print(f\"\\nProcessing video: {video_path}\")\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error opening video: {video_path}\")\n",
    "            return None\n",
    "\n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = total_frames / fps\n",
    "\n",
    "        print(\n",
    "            f\"Video properties: {fps} FPS, {total_frames} frames, {duration:.2f}s duration\"\n",
    "        )\n",
    "\n",
    "        frame_predictions = []\n",
    "        frame_idx = 0\n",
    "\n",
    "        # Process frames at specified sample rate\n",
    "        frame_interval = max(1, fps // sample_rate) if fps > sample_rate else 1\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_idx % frame_interval == 0:\n",
    "                # Convert BGR to RGB\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Predict\n",
    "                prediction = self.predict_frame(frame_rgb, frame_idx)\n",
    "                if prediction:\n",
    "                    prediction[\"timestamp\"] = frame_idx / fps\n",
    "                    frame_predictions.append(prediction)\n",
    "\n",
    "                    if len(frame_predictions) % 100 == 0:\n",
    "                        print(f\"Processed {len(frame_predictions)} frames...\")\n",
    "\n",
    "            frame_idx += 1\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        # Compile video results\n",
    "        video_result = self.compile_video_results(\n",
    "            video_path, frame_predictions, fps, total_frames, duration\n",
    "        )\n",
    "\n",
    "        return video_result\n",
    "\n",
    "    def compile_video_results(\n",
    "        self, video_path, frame_predictions, fps, total_frames, duration\n",
    "    ):\n",
    "        \"\"\"Compile results for a single video\"\"\"\n",
    "        if not frame_predictions:\n",
    "            return None\n",
    "\n",
    "        # Convert to DataFrame for easier analysis\n",
    "        df = pd.DataFrame(frame_predictions)\n",
    "\n",
    "        # Calculate statistics\n",
    "        tti_predictions = df[df[\"prediction\"] == 1]\n",
    "        no_tti_predictions = df[df[\"prediction\"] == 0]\n",
    "\n",
    "        total_predictions = len(df)\n",
    "        tti_count = len(tti_predictions)\n",
    "        no_tti_count = len(no_tti_predictions)\n",
    "\n",
    "        tti_percentage = (tti_count / total_predictions) * 100\n",
    "        avg_tti_confidence = (\n",
    "            tti_predictions[\"confidence\"].mean() if tti_count > 0 else 0\n",
    "        )\n",
    "        avg_no_tti_confidence = (\n",
    "            no_tti_predictions[\"confidence\"].mean() if no_tti_count > 0 else 0\n",
    "        )\n",
    "\n",
    "        # Time-based analysis\n",
    "        tti_duration = tti_count * (duration / total_predictions)\n",
    "\n",
    "        video_result = {\n",
    "            \"video_path\": video_path,\n",
    "            \"video_name\": Path(video_path).name,\n",
    "            \"video_properties\": {\n",
    "                \"fps\": fps,\n",
    "                \"total_frames\": total_frames,\n",
    "                \"duration_seconds\": duration,\n",
    "                \"frames_processed\": total_predictions,\n",
    "            },\n",
    "            \"predictions\": {\n",
    "                \"total_predictions\": total_predictions,\n",
    "                \"tti_count\": tti_count,\n",
    "                \"no_tti_count\": no_tti_count,\n",
    "                \"tti_percentage\": tti_percentage,\n",
    "                \"no_tti_percentage\": 100 - tti_percentage,\n",
    "            },\n",
    "            \"confidence_stats\": {\n",
    "                \"avg_tti_confidence\": avg_tti_confidence,\n",
    "                \"avg_no_tti_confidence\": avg_no_tti_confidence,\n",
    "                \"overall_avg_confidence\": df[\"confidence\"].mean(),\n",
    "            },\n",
    "            \"temporal_analysis\": {\n",
    "                \"tti_duration_seconds\": tti_duration,\n",
    "                \"tti_duration_percentage\": (tti_duration / duration) * 100,\n",
    "            },\n",
    "            \"frame_predictions\": frame_predictions,\n",
    "        }\n",
    "\n",
    "        return video_result\n",
    "\n",
    "    def process_multiple_videos(self, video_folder, output_folder=\"results\"):\n",
    "        \"\"\"Process multiple videos and generate comprehensive report\"\"\"\n",
    "        video_folder = Path(video_folder)\n",
    "        output_folder = Path(output_folder)\n",
    "        output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "        # Find video files\n",
    "        video_extensions = [\".mp4\", \".avi\", \".mov\", \".mkv\"]\n",
    "        video_files = []\n",
    "        for ext in video_extensions:\n",
    "            video_files.extend(video_folder.glob(f\"*{ext}\"))\n",
    "\n",
    "        print(f\"Found {len(video_files)} video files\")\n",
    "\n",
    "        all_results = []\n",
    "\n",
    "        # Process each video\n",
    "        for video_file in video_files:\n",
    "            try:\n",
    "                result = self.process_video(str(video_file))\n",
    "                if result:\n",
    "                    all_results.append(result)\n",
    "                    print(f\"‚úì Processed: {video_file.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚úó Error processing {video_file.name}: {e}\")\n",
    "\n",
    "        # Generate comprehensive report\n",
    "        if all_results:\n",
    "            self.generate_comprehensive_report(all_results, output_folder)\n",
    "\n",
    "        return all_results\n",
    "\n",
    "    def generate_comprehensive_report(self, all_results, output_folder):\n",
    "        \"\"\"Generate detailed analysis report\"\"\"\n",
    "        output_folder = Path(output_folder)\n",
    "\n",
    "        # Create summary DataFrame\n",
    "        summary_data = []\n",
    "        for result in all_results:\n",
    "            summary_data.append(\n",
    "                {\n",
    "                    \"Video Name\": result[\"video_name\"],\n",
    "                    \"Duration (s)\": result[\"video_properties\"][\"duration_seconds\"],\n",
    "                    \"Total Frames Processed\": result[\"predictions\"][\n",
    "                        \"total_predictions\"\n",
    "                    ],\n",
    "                    \"TTI Count\": result[\"predictions\"][\"tti_count\"],\n",
    "                    \"TTI Percentage\": result[\"predictions\"][\"tti_percentage\"],\n",
    "                    \"Avg TTI Confidence\": result[\"confidence_stats\"][\n",
    "                        \"avg_tti_confidence\"\n",
    "                    ],\n",
    "                    \"TTI Duration (s)\": result[\"temporal_analysis\"][\n",
    "                        \"tti_duration_seconds\"\n",
    "                    ],\n",
    "                    \"TTI Time Percentage\": result[\"temporal_analysis\"][\n",
    "                        \"tti_duration_percentage\"\n",
    "                    ],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "        # Save summary to CSV\n",
    "        summary_df.to_csv(output_folder / \"video_analysis_summary.csv\", index=False)\n",
    "\n",
    "        # Generate detailed report\n",
    "        report_path = output_folder / \"detailed_analysis_report.txt\"\n",
    "\n",
    "        with open(report_path, \"w\") as f:\n",
    "            f.write(\"TTI MODEL INFERENCE RESULTS - BILE DUCT INJURY VIDEOS\\n\")\n",
    "            f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "            f.write(\n",
    "                f\"Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
    "            )\n",
    "            f.write(f\"Total Videos Processed: {len(all_results)}\\n\\n\")\n",
    "\n",
    "            # Overall Statistics\n",
    "            f.write(\"OVERALL STATISTICS\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            f.write(\n",
    "                f\"Total Processing Time: {summary_df['Duration (s)'].sum():.2f} seconds\\n\"\n",
    "            )\n",
    "            f.write(\n",
    "                f\"Total Frames Processed: {summary_df['Total Frames Processed'].sum():,}\\n\"\n",
    "            )\n",
    "            f.write(\n",
    "                f\"Average TTI Percentage: {summary_df['TTI Percentage'].mean():.2f}%\\n\"\n",
    "            )\n",
    "            f.write(\n",
    "                f\"TTI Percentage Range: {summary_df['TTI Percentage'].min():.2f}% - {summary_df['TTI Percentage'].max():.2f}%\\n\"\n",
    "            )\n",
    "            f.write(\n",
    "                f\"Average TTI Confidence: {summary_df['Avg TTI Confidence'].mean():.3f}\\n\\n\"\n",
    "            )\n",
    "\n",
    "            # Per-video detailed results\n",
    "            f.write(\"PER-VIDEO DETAILED RESULTS\\n\")\n",
    "            f.write(\"-\" * 30 + \"\\n\")\n",
    "\n",
    "            for i, result in enumerate(all_results, 1):\n",
    "                f.write(f\"\\n{i}. {result['video_name']}\\n\")\n",
    "                f.write(\n",
    "                    f\"   Duration: {result['video_properties']['duration_seconds']:.2f}s\\n\"\n",
    "                )\n",
    "                f.write(\n",
    "                    f\"   Frames Processed: {result['predictions']['total_predictions']:,}\\n\"\n",
    "                )\n",
    "                f.write(\n",
    "                    f\"   TTI Interactions: {result['predictions']['tti_count']} ({result['predictions']['tti_percentage']:.2f}%)\\n\"\n",
    "                )\n",
    "                f.write(\n",
    "                    f\"   No-TTI: {result['predictions']['no_tti_count']} ({result['predictions']['no_tti_percentage']:.2f}%)\\n\"\n",
    "                )\n",
    "                f.write(\n",
    "                    f\"   Average TTI Confidence: {result['confidence_stats']['avg_tti_confidence']:.3f}\\n\"\n",
    "                )\n",
    "                f.write(\n",
    "                    f\"   TTI Duration: {result['temporal_analysis']['tti_duration_seconds']:.2f}s ({result['temporal_analysis']['tti_duration_percentage']:.2f}%)\\n\"\n",
    "                )\n",
    "\n",
    "        # Generate visualizations\n",
    "        self.generate_visualizations(all_results, summary_df, output_folder)\n",
    "\n",
    "        print(f\"\\n‚úì Comprehensive report saved to: {output_folder}\")\n",
    "        print(f\"‚úì Summary CSV: {output_folder / 'video_analysis_summary.csv'}\")\n",
    "        print(f\"‚úì Detailed report: {report_path}\")\n",
    "\n",
    "    def generate_visualizations(self, all_results, summary_df, output_folder):\n",
    "        \"\"\"Generate visualization plots\"\"\"\n",
    "        plt.style.use(\"default\")\n",
    "\n",
    "        # 1. TTI Percentage Distribution\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "        # TTI Percentage by Video\n",
    "        axes[0, 0].bar(range(len(summary_df)), summary_df[\"TTI Percentage\"])\n",
    "        axes[0, 0].set_title(\"TTI Percentage by Video\")\n",
    "        axes[0, 0].set_xlabel(\"Video Index\")\n",
    "        axes[0, 0].set_ylabel(\"TTI Percentage (%)\")\n",
    "        axes[0, 0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "        # TTI Confidence Distribution\n",
    "        axes[0, 1].hist(summary_df[\"Avg TTI Confidence\"].dropna(), bins=15, alpha=0.7)\n",
    "        axes[0, 1].set_title(\"TTI Confidence Distribution\")\n",
    "        axes[0, 1].set_xlabel(\"Average TTI Confidence\")\n",
    "        axes[0, 1].set_ylabel(\"Frequency\")\n",
    "\n",
    "        # TTI Duration vs Video Duration\n",
    "        axes[1, 0].scatter(summary_df[\"Duration (s)\"], summary_df[\"TTI Duration (s)\"])\n",
    "        axes[1, 0].set_title(\"TTI Duration vs Total Video Duration\")\n",
    "        axes[1, 0].set_xlabel(\"Video Duration (s)\")\n",
    "        axes[1, 0].set_ylabel(\"TTI Duration (s)\")\n",
    "\n",
    "        # TTI Time Percentage\n",
    "        axes[1, 1].bar(range(len(summary_df)), summary_df[\"TTI Time Percentage\"])\n",
    "        axes[1, 1].set_title(\"TTI Time Percentage by Video\")\n",
    "        axes[1, 1].set_xlabel(\"Video Index\")\n",
    "        axes[1, 1].set_ylabel(\"TTI Time Percentage (%)\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            output_folder / \"analysis_overview.png\", dpi=300, bbox_inches=\"tight\"\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        # 2. Temporal Analysis for each video\n",
    "        for result in all_results[:3]:  # Show first 3 videos to avoid overcrowding\n",
    "            self.plot_temporal_analysis(result, output_folder)\n",
    "\n",
    "    def plot_temporal_analysis(self, video_result, output_folder):\n",
    "        \"\"\"Plot temporal analysis for individual video\"\"\"\n",
    "        df = pd.DataFrame(video_result[\"frame_predictions\"])\n",
    "\n",
    "        plt.figure(figsize=(15, 8))\n",
    "\n",
    "        # Plot predictions over time\n",
    "        plt.subplot(2, 1, 1)\n",
    "        colors = [\"blue\" if p == 0 else \"red\" for p in df[\"prediction\"]]\n",
    "        plt.scatter(df[\"timestamp\"], df[\"prediction\"], c=colors, alpha=0.6, s=10)\n",
    "        plt.title(f'TTI Predictions Over Time - {video_result[\"video_name\"]}')\n",
    "        plt.ylabel(\"Prediction (0: No-TTI, 1: TTI)\")\n",
    "        plt.ylim(-0.1, 1.1)\n",
    "\n",
    "        # Plot confidence over time\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(df[\"timestamp\"], df[\"confidence\"], alpha=0.7, linewidth=0.8)\n",
    "        plt.title(\"Prediction Confidence Over Time\")\n",
    "        plt.xlabel(\"Time (seconds)\")\n",
    "        plt.ylabel(\"Confidence\")\n",
    "        plt.ylim(0, 1)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        video_name_clean = video_result[\"video_name\"].replace(\".\", \"_\")\n",
    "        plt.savefig(\n",
    "            output_folder / f\"temporal_analysis_{video_name_clean}.png\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e75395a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTI Model Inference on Bile Duct Injury Videos\n",
      "==================================================\n",
      "\n",
      "Attempting to load: ./models/ViT/best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct loading failed, trying flexible loading...\n",
      "Skipping layer first.weight (shape mismatch or not found)\n",
      "Skipping layer pre_conv.weight (shape mismatch or not found)\n",
      "‚úì Loaded model with 202/204 layers matched\n",
      "‚úì Successfully loaded model: ./models/ViT/best_model.pt\n",
      "Found 1 video files\n",
      "\n",
      "Processing video: bdi_videos/V15_Trimmed.mp4\n",
      "Video properties: 25 FPS, 3547 frames, 141.88s duration\n",
      "Processed 100 frames...\n",
      "Processed 200 frames...\n",
      "Processed 300 frames...\n",
      "Processed 400 frames...\n",
      "Processed 500 frames...\n",
      "Processed 600 frames...\n",
      "Processed 700 frames...\n",
      "Processed 800 frames...\n",
      "Processed 900 frames...\n",
      "Processed 1000 frames...\n",
      "Processed 1100 frames...\n",
      "Processed 1200 frames...\n",
      "Processed 1300 frames...\n",
      "Processed 1400 frames...\n",
      "Processed 1500 frames...\n",
      "Processed 1600 frames...\n",
      "Processed 1700 frames...\n",
      "Processed 1800 frames...\n",
      "Processed 1900 frames...\n",
      "Processed 2000 frames...\n",
      "Processed 2100 frames...\n",
      "Processed 2200 frames...\n",
      "Processed 2300 frames...\n",
      "Processed 2400 frames...\n",
      "Processed 2500 frames...\n",
      "Processed 2600 frames...\n",
      "Processed 2700 frames...\n",
      "Processed 2800 frames...\n",
      "Processed 2900 frames...\n",
      "Processed 3000 frames...\n",
      "Processed 3100 frames...\n",
      "Processed 3200 frames...\n",
      "Processed 3300 frames...\n",
      "Processed 3400 frames...\n",
      "Processed 3500 frames...\n",
      "‚úì Processed: V15_Trimmed.mp4\n",
      "\n",
      "‚úì Comprehensive report saved to: tti_inference_results\n",
      "‚úì Summary CSV: tti_inference_results/video_analysis_summary.csv\n",
      "‚úì Detailed report: tti_inference_results/detailed_analysis_report.txt\n",
      "\n",
      "‚úÖ Successfully processed 1 videos\n",
      "üìä Results saved to: tti_inference_results/\n",
      "\n",
      "üìà QUICK SUMMARY:\n",
      "   Total frames analyzed: 3,547\n",
      "   Total TTI detections: 1,340\n",
      "   Overall TTI percentage: 37.78%\n"
     ]
    }
   ],
   "source": [
    "model_candidates = [\n",
    "    \"./models/ViT/best_model.pt\",\n",
    "    # \"./EffNet_B3/best_model.pt\",\n",
    "    # \"./EffNet_B0/best_model.pt\",\n",
    "    # \"./EffNet_B1/best_model.pt\",\n",
    "]\n",
    "\n",
    "video_folder = \"./bdi_videos\"\n",
    "output_folder = \"./bdi_vit_results\"\n",
    "\n",
    "print(\"TTI Model Inference on Bile Duct Injury Videos\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Try loading models in order of preference\n",
    "inference_pipeline = None\n",
    "for model_path in model_candidates:\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"\\nAttempting to load: {model_path}\")\n",
    "        try:\n",
    "            inference_pipeline = TTI_VideoInference(model_path)\n",
    "            if inference_pipeline.model is not None:\n",
    "                print(f\"‚úì Successfully loaded model: {model_path}\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Failed to load {model_path}: {e}\")\n",
    "            continue\n",
    "    else:\n",
    "        print(f\"‚úó Model not found: {model_path}\")\n",
    "\n",
    "if inference_pipeline is None or inference_pipeline.model is None:\n",
    "    print(\"‚ùå Could not load any model. Please check model paths and files.\")\n",
    "    exit()\n",
    "\n",
    "# Process all videos\n",
    "results = inference_pipeline.process_multiple_videos(video_folder, output_folder)\n",
    "\n",
    "if results:\n",
    "    print(f\"\\n‚úÖ Successfully processed {len(results)} videos\")\n",
    "    print(f\"üìä Results saved to: {output_folder}/\")\n",
    "\n",
    "    # Print quick summary\n",
    "    total_tti = sum(r[\"predictions\"][\"tti_count\"] for r in results)\n",
    "    total_frames = sum(r[\"predictions\"][\"total_predictions\"] for r in results)\n",
    "    avg_tti_percentage = (total_tti / total_frames) * 100 if total_frames > 0 else 0\n",
    "\n",
    "    print(f\"\\nüìà QUICK SUMMARY:\")\n",
    "    print(f\"   Total frames analyzed: {total_frames:,}\")\n",
    "    print(f\"   Total TTI detections: {total_tti:,}\")\n",
    "    print(f\"   Overall TTI percentage: {avg_tti_percentage:.2f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No videos were successfully processed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
